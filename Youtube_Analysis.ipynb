{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Comments Sentiment Analysis\n",
    "Andie Donovan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Basic Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basics\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read Data\n",
    "Note that we have to use encoding = \"latin-1\" instead of UTF-8 because we have foreign languages present\n",
    "The different encodings treat characters differently (in latin-1 each character is only one byte long whereas in utf-8 it can me more than one byte in length). Typically utf-8 captures more types of characters, so it was surprising that we had to use latin-8. \n",
    "* for later: look into this more: http://www.unicode.org/reports/tr10/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/andiedonovan/myProjects/Youtube_Python_Project/AndiesBranch/data/') # change directory\n",
    "df = pd.read_csv('OKGOcomments.csv', delimiter=\";\", skiprows=2, encoding='latin-1', engine='python') # read in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Clean Data Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "df.columns = [\n",
    "  'label',\n",
    "  'comment','a','b'\n",
    "]\n",
    "df = df.drop(['a', 'b'], axis = 1).dropna() # drop column 3 and missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Remove non-alphabetic characters (including numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in range(len(df)):\n",
    "    line = df.iloc[row,1]\n",
    "    df.iloc[row,1] = re.sub(\"[^a-zA-Z]\", \" \", line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Import sklearn and nltk packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andiedonovan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/andiedonovan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tokenize Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['com_token']=df['comment'].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andiedonovan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "df['com_remv']=df['com_token'].apply(lambda x: [y for y in x if y not in sw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Lemmatization (and Stemming?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "df[\"com_lemma\"] = df['com_remv'] \\\n",
    "    .apply(lambda x : [lemmatizer.lemmatize(y) for y in x]) # lemmatization\n",
    "\n",
    "df['com_stem']=df['com_lemma'] \\\n",
    "    .apply(lambda x : [ps.stem(y) for y in x]) # stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Split into Training and Test Data\n",
    "Using a pre-defined train-test-split function, we randomly split the data into training data (75%) and test data (25%). We set the x variable for both to the comments, since these are the attributes we will use for classificationand the y variable to the label, as this is what we are trying to predict. The random_state paramteter is simply for reproducability (otherwise the function would produce a different split every time we ran it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn # machine learning\n",
    "from sklearn.model_selection import train_test_split # splitting up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"com_stem_str\"] = df[\"com_stem\"].apply(', '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>com_token</th>\n",
       "      <th>com_remv</th>\n",
       "      <th>com_lemma</th>\n",
       "      <th>com_stem</th>\n",
       "      <th>com_stem_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>Everyone knows brand s papers from  But  No on...</td>\n",
       "      <td>[everyone, knows, brand, s, papers, from, but,...</td>\n",
       "      <td>[everyone, knows, brand, papers, one, knows, w...</td>\n",
       "      <td>[everyone, know, brand, paper, one, know, welf...</td>\n",
       "      <td>[everyon, know, brand, paper, one, know, welfa...</td>\n",
       "      <td>everyon, know, brand, paper, one, know, welfar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Your paper cut balance is</td>\n",
       "      <td>[your, paper, cut, balance, is]</td>\n",
       "      <td>[paper, cut, balance]</td>\n",
       "      <td>[paper, cut, balance]</td>\n",
       "      <td>[paper, cut, balanc]</td>\n",
       "      <td>paper, cut, balanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>OH SHIT WHEN I SAW THIS ON MY FRONT PAGE      ...</td>\n",
       "      <td>[oh, shit, when, i, saw, this, on, my, front, ...</td>\n",
       "      <td>[oh, shit, saw, front, page, love, song]</td>\n",
       "      <td>[oh, shit, saw, front, page, love, song]</td>\n",
       "      <td>[oh, shit, saw, front, page, love, song]</td>\n",
       "      <td>oh, shit, saw, front, page, love, song</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0   -1.0  Everyone knows brand s papers from  But  No on...   \n",
       "1    0.0         Your paper cut balance is                    \n",
       "2    1.0  OH SHIT WHEN I SAW THIS ON MY FRONT PAGE      ...   \n",
       "\n",
       "                                           com_token  \\\n",
       "0  [everyone, knows, brand, s, papers, from, but,...   \n",
       "1                    [your, paper, cut, balance, is]   \n",
       "2  [oh, shit, when, i, saw, this, on, my, front, ...   \n",
       "\n",
       "                                            com_remv  \\\n",
       "0  [everyone, knows, brand, papers, one, knows, w...   \n",
       "1                              [paper, cut, balance]   \n",
       "2           [oh, shit, saw, front, page, love, song]   \n",
       "\n",
       "                                           com_lemma  \\\n",
       "0  [everyone, know, brand, paper, one, know, welf...   \n",
       "1                              [paper, cut, balance]   \n",
       "2           [oh, shit, saw, front, page, love, song]   \n",
       "\n",
       "                                            com_stem  \\\n",
       "0  [everyon, know, brand, paper, one, know, welfa...   \n",
       "1                               [paper, cut, balanc]   \n",
       "2           [oh, shit, saw, front, page, love, song]   \n",
       "\n",
       "                                        com_stem_str  \n",
       "0  everyon, know, brand, paper, one, know, welfar...  \n",
       "1                                 paper, cut, balanc  \n",
       "2             oh, shit, saw, front, page, love, song  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "                                    df[\"com_stem_str\"], df[\"label\"], \n",
    "                                    test_size=0.25, \n",
    "                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure all of the data looks good:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths training variables:  1495 , 1495\n",
      "lengths testing variables:  499 , 499 \n",
      "\n",
      "Are there any missing values? \n",
      " * Training: False , False \n",
      " * Testing:  False , False\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "print('lengths training variables: ', len(X_train),\",\", len(Y_train))\n",
    "print('lengths testing variables: ', len(X_test),\",\", len(Y_test), '\\n')\n",
    "\n",
    "print('Are there any missing values?', \n",
    "      '\\n * Training:', pd.isnull(X_train).values.any(), ',', pd.isnull(Y_train).values.any(), \n",
    "      '\\n * Testing: ', pd.isnull(X_test).values.any(), \",\", pd.isnull(Y_test).values.any())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test) # we have a pandas core Series; we just want the comments in an array without numbering\n",
    "# help(X_test) # use values attribute\n",
    "# we will want to use X_test.values(), Y_train.values(), .... to just access the data in list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "893                             actual, hype, great, fire\n",
       "1676                             damian, even, come, idea\n",
       "416     like, print, paper, set, pre, print, put, pape...\n",
       "Name: com_stem_str, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 TF-IDF Transformation\n",
    "Documentation: [Scikit-Learn Documentation]('http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#exercise-2-sentiment-analysis-on-movie-reviews')\n",
    "\n",
    "We want to initialize a Count Vectorizer, which will convert the comments to a matrix of token (word) counts. This produces a sparse representation of the counts\n",
    "We then fit the model using our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Transform Data to Counts \n",
    "source: https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/\n",
    "\n",
    "instead of just counting the number of occurences bluntly, the term frequency inverse document frequency transformation weights words based on their number of occurences in each document (aka comment) compared to occurences in the entire corpus (aka collection of comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "xtrain = tfidf.fit_transform(X_train)\n",
    "xtest = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(xtrain.vocabulary_)\n",
    "#print(xtrain.idf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 MNB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(xtrain, Y_train) # fit the model on the training data word counts and training data lables\n",
    "mnb_predict = mnb.predict(xtest) # make our y predictions (labels) on the comment test data\n",
    "for i in mnb_predict[:5]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1  Make MNB Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics # for accuracy/ precision\n",
    "mnb_predict = mnb.predict(xtest) # make our y predictions (labels) on the comment test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1.0: 12, 0.0: 315, 1.0: 172}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(mnb_predict, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 MNB Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.625251 % accuracy for the model \n",
      " \n",
      "\n",
      "Here is the Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.83      0.09      0.17       106\n",
      "        0.0       0.59      0.83      0.69       226\n",
      "        1.0       0.67      0.69      0.68       167\n",
      "\n",
      "avg / total       0.67      0.63      0.58       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_acc = metrics.accuracy_score(Y_test, mnb_predict)\n",
    "print('We obtained ', round(mnb_acc, 6), '% accuracy for the model \\n \\n')\n",
    "np.mean(mnb_predict == Y_test)  # same score, different method\n",
    "print('Here is the Classification Report: \\n')\n",
    "print(metrics.classification_report(Y_test, mnb_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 MNB Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the Confusion Matrix: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 10,  76,  20],\n",
       "       [  2, 187,  37],\n",
       "       [  0,  52, 115]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Here is the Confusion Matrix: \\n')\n",
    "metrics.confusion_matrix(Y_test, mnb_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Using the SGD (Stochastic Gradient Descent) Learning \n",
    "> \"The gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning, see the partial_fit method. For best results using the default learning rate schedule, the data should have zero mean and unit variance. This implementation works with data represented as dense or sparse arrays of floating point values for the features. The model it fits can be controlled with the loss parameter; by default, it fits a linear support vector machine (SVM).\"\n",
    "[Scikit-Learn Documenttion](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    "\n",
    "\n",
    "Essentially SGD tries to find an extrema through iteration. In this case we are dealing with likelihood functions in which each algorithm tries to find the classification (positive, neutral or negative) with the highest likelihood of occuring (or probability of being correct in a sense). We want to maximize this likelihood while minimizing inaccuracies (Type I/ Type II Errors) and computational expenditure. We might have to revisit material on [Statistical Powers](https://en.wikipedia.org/wiki/Statistical_power). The count vectorizer transformation converts our data to a sparse matrix, which represents the model features (aka comments & their word counts) in matrix-form where the majority of the entries are zero. \n",
    "\n",
    "\n",
    "\n",
    "**Loss-Functions**: maps different events to a \"cost\" or price paid for inaccuracy of predictions/ classifications. Purpose is to choose the optimal loss function (aka try to minimize costly inaccuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier # Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.639279 % accuracy for the logistic regression model\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='log', penalty='l2', alpha=1e-3, max_iter=5, tol=None, random_state=1) \n",
    "sgd.fit(xtrain, Y_train)\n",
    "sgd_predict = sgd.predict(xtest)\n",
    "sgd_acc = metrics.accuracy_score(Y_test, sgd_predict)\n",
    "print('We obtained ', round(sgd_acc, 6), '% accuracy for the logistic regression model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifier Parameters:**\n",
    "* loss parameter set to 'log' to use logistic regression\n",
    "* penalty: regularization term; sparsity or feature selection\n",
    "    * the process of introducing additional information in order to prevent overfitting/ sparsity overlaps: [regularization](https://en.wikipedia.org/wiki/Regularization_(mathematics))\n",
    "* alpha: smoothing parameter? \n",
    "* max_iter: how many times to pass over the training data\n",
    "* tol: stopping criterion; counts losses\n",
    "* verbosity - using more factors than necessary; want to maximize parsimony"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Linear Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.653307 % accuracy for the SVM model\n"
     ]
    }
   ],
   "source": [
    "svm = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=5, tol=None, random_state=1) # penalty, loss, alpha paramters\n",
    "svm.fit(xtrain, Y_train)\n",
    "svm_predict = svm.predict(xtest)\n",
    "svm_acc = metrics.accuracy_score(Y_test, svm_predict)\n",
    "print('We obtained ', round(svm_acc, 6), '% accuracy for the SVM model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the loss parameter to 'hinge' to use linear SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0 Esemble Learning\n",
    "[link](http://scikit-learn.org/stable/modules/ensemble.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier # bagging ensemble method\n",
    "from sklearn.ensemble import RandomForestClassifier # random forest ensemble method\n",
    "from sklearn.neighbors import KNeighborsClassifier # k-NN ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.593186 % accuracy for the Bagging model\n"
     ]
    }
   ],
   "source": [
    "bagcls = BaggingClassifier(KNeighborsClassifier(),\n",
    "                            max_samples=0.5, max_features=0.5)\n",
    "bagcls = bagcls.fit(xtrain, Y_train)\n",
    "\n",
    "bag_predict = bagcls.predict(xtest)\n",
    "bag_acc = metrics.accuracy_score(Y_test, bag_predict)\n",
    "print('We obtained ', round(bag_acc, 6), '% accuracy for the Bagging model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained  0.659319 % accuracy for the Random Forest model\n"
     ]
    }
   ],
   "source": [
    "ranfor = RandomForestClassifier(n_estimators=10)\n",
    "ranfor = ranfor.fit(xtrain, Y_train)\n",
    "\n",
    "rf_predict = ranfor.predict(xtest)\n",
    "rf_acc = metrics.accuracy_score(Y_test, rf_predict)\n",
    "print('We obtained ', round(rf_acc, 6), '% accuracy for the Random Forest model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.0 Data Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Table of Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myTable = pd.DataFrame(columns=['MNB','SGD','LR', 'LSV', 'Bag', 'RF'],\n",
    "                   index=[\"Acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MNB</th>\n",
       "      <th>SGD</th>\n",
       "      <th>LR</th>\n",
       "      <th>LSV</th>\n",
       "      <th>Bag</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acc</th>\n",
       "      <td>0.61523</td>\n",
       "      <td>0.651303</td>\n",
       "      <td>0.651303</td>\n",
       "      <td>0.665331</td>\n",
       "      <td>0.53507</td>\n",
       "      <td>0.637275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MNB       SGD        LR       LSV      Bag        RF\n",
       "Acc  0.61523  0.651303  0.651303  0.665331  0.53507  0.637275"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTable['MNB']=mnb_acc; myTable['SGD']=sgd_acc; myTable['LR']=sgd_acc\n",
    "myTable['LSV']= svm_acc; myTable['Bag']= bag_acc; myTable['RF']= rf_acc\n",
    "myTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.0 Results\n",
    "\n",
    "From the 6 different machine learning models attempted, Linear Support Vector Machine gave the highest accuracy. Converseley, KNN gave the lowest accuracy.\n",
    "\n",
    "### Next Steps: \n",
    "* look into why MNB performed worse with tf-idf transformed data (while the rest seemed to improve)\n",
    "* look into the benefits of stemming as opposed to lemmatization\n",
    "* word tagging, n-grams \n",
    "* apply grid search to determine optimal parameters, especially for models like random forest where it can make a big difference in the model performance\n",
    "* apply a mulitlayer perceptron neural network (with grid search for layers and blocks)\n",
    "* figure out why plotly dashboard does not rendering offline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Notes: \n",
    "1. Feature Engineering:\n",
    "    * Look at Peter Norvig's [Spelling Corrector](http://norvig.com/spell-correct.html)\n",
    "    * Meta Features, Stemming, Speech Tagging, etc.:\n",
    "        * [NLP Blog Post](http://www.vikparuchuri.com/blog/natural-language-processing-tutorial/)\n",
    "        * [Stanford Post](https://nlp.stanford.edu/IR-book/html/htmledition/features-for-text-1.html)\n",
    "3. Add more videos/ comments for diversity of diction/ sentiments\n",
    "4. Print comments and their predicted classification: highlight the correct ones in green and the wrong ones in red\n",
    "5. Data Visualization / Dashboard Resources:\n",
    "    * [Plotly](https://plot.ly/python/create-online-dashboard/)\n",
    "    * [Tutorial](https://moderndata.plot.ly/create-a-plotly-dashboards-in-under-10-minutes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
